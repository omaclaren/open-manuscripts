{
 "metadata": {
  "name": "",
  "signature": "sha256:8591e783e7c7e2b2c21c157ec7c4efff1b4eeaf6e3e67e10505b2509fee73ef6"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Data analysis functions notebook  \n",
      "OJM  \n",
      "Can run from another using e.g. %run OR can define a function to execute desired cells  \n",
      "See - http://stackoverflow.com/questions/16966280/reusing-code-from-different-ipython-notebooks  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pandas as pd\n",
      "from scipy import stats\n",
      "import scipy.interpolate as interpolate\n",
      "import scipy.special as special\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import os\n",
      "import errno\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def test_function(a=1.0):\n",
      "    print a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####File manipulation"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_data_file(data_dir= '../data-working/TXT_BrdU/',goal_time= '0060',time_units='min'):\n",
      "    \"\"\"\n",
      "    finds full name of a data file (in a given dir) corresponding to given time\n",
      "    \"\"\"\n",
      "    import os\n",
      "    files_in_dir= os.listdir(data_dir)\n",
      "    files_in_dir.sort()\n",
      "\n",
      "    data_file= ''\n",
      "    for file in files_in_dir:\n",
      "        i= file.find(time_units)\n",
      "        time= file[i-len(goal_time):i]#\n",
      "        if time == goal_time:\n",
      "            data_file= file\n",
      "    return data_file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Lengths"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_lengths_in_sample(data_dir='../data-working/TXT_BrdU/',file_to_fit = 'BrdU_01_0060min.txt',sample_type='BrdU',output_path='../figures/length_analysis/',min_length=20,max_length=90,do_plot=True):\n",
      "    #Some todos\n",
      "    #- get rid of magic end of line 'txt' chomp, replace with check.\n",
      "    #k=3\n",
      "    #s=6\n",
      "    #\n",
      "    import os, errno\n",
      "    import matplotlib.pyplot as plt\n",
      "\n",
      "    #data= np.genfromtxt(data_dir+file_to_fit,delimiter=\",\")\n",
      "    data_panda= pd.read_csv(data_dir+file_to_fit,header=None,names=range(int(max_length)),dtype='float')\n",
      "    #data_panda.convert_objects(convert_numeric=True)\n",
      "    data= data_panda.values\n",
      "    \n",
      "    print 'here'\n",
      "    print data\n",
      "    #get finite values and count size\n",
      "    num_data_rows= data.shape[0]\n",
      "    lengths= np.zeros(num_data_rows)\n",
      "    \n",
      "    print 'here2'\n",
      "    print num_data_rows\n",
      "    print data[0,:]\n",
      "    #print np.isfinite(data[0,19])\n",
      "    \n",
      "    for i in range(0,num_data_rows):\n",
      "        lengths[i]= data[i,np.isfinite(data[i,:])].size\n",
      "    binwidth=1.5 #NOTE - AFFECTS INTERP?\n",
      "    print lengths\n",
      "    \n",
      "    if do_plot:\n",
      "        plt.hist(lengths, bins=np.arange(min(lengths), max(lengths) + binwidth, binwidth),histtype='stepfilled', normed=False, color='b',label=file_to_fit[:-4]+\"\\ntotal strips:\"+str(lengths.size))\n",
      "        #plt.hist(lengths,label=file_to_fit)\n",
      "        plt.xlabel(\"Strip length (cells)\")\n",
      "        plt.ylabel(\"Frequency\")\n",
      "        plt.xlim(min_length,max_length)\n",
      "        plt.legend(loc=2)\n",
      "        #plt.text(0.8,0.8,\"total samples:\\n\"+str(np.sum(lengths)))\n",
      "        plt.axvline(lengths.mean(), color='r',linestyle='dashed',linewidth=2)\n",
      "        #plt.axvline(lengths.mode(), color='r', linestyle='dashed', linewidth=3)\n",
      "\n",
      "        save_path= output_path+sample_type+'/'\n",
      "        try:\n",
      "            os.makedirs(save_path)\n",
      "        except OSError as exc: # Python >2.5\n",
      "            if exc.errno == errno.EEXIST and os.path.isdir(save_path):\n",
      "                pass\n",
      "            else: raise\n",
      "        plt.savefig(save_path+'sample-length-distribution-'+file_to_fit[:-4]+'.pdf')\n",
      "        plt.show()\n",
      "    \n",
      "    return lengths\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "####Densities"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def process_and_fit_label_data_file(data_dir='../data-working/TXT_BrdU/',file_to_fit='BrdU_01_0060min.txt',sample_type='BrdU',output_path='../figures/density_profiles/',k=3,s=15,x_min=0.0,x_max=90.0,y_min=0.0,y_max=1.0,do_plot=False):\n",
      "    '''\n",
      "    Fits a density function to cell counts.\n",
      "    -\n",
      "    label_mean_profile\n",
      "    label_l_err\n",
      "    label_r_err\n",
      "    label_smoothed_f\n",
      "    -\n",
      "    '''\n",
      "    from scipy import stats\n",
      "    import os, errno #for file I/O and error handling - see: http://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python\n",
      "    import scipy.interpolate as interpolate\n",
      "    import scipy.special as special\n",
      "    \n",
      "    #--basic processing\n",
      "    #read in\n",
      "    #data= np.genfromtxt(data_dir+file_to_fit,delimiter=\",\") #Load data from a text file, with missing values handled as specified\n",
      "    print 'here'\n",
      "    print data_dir+file_to_fit\n",
      "    data_panda= pd.read_csv(data_dir+file_to_fit,header=None,names=range(int(x_max)),dtype='float')\n",
      "    #data_panda.convert_objects(convert_numeric=True)\n",
      "    data= data_panda.values\n",
      "    \n",
      "    #print data\n",
      "    #print data[0,:]\n",
      "    \n",
      "    #convert to binary labelled/unlabelled (careful of NAs! - E.g. for lengths doesn't work.)\n",
      "    data_binary= np.copy(data[:,:]) #separate copies! Re tags vs. variables.\n",
      "    #data_binary[np.logical_or(data_binary==8,data_binary==2)] = -1\n",
      "    #labelled\n",
      "    data_binary[(data_binary==2)|(data_binary==3)|(data_binary==8)|(data_binary==9)]=-1\n",
      "    #unlabelled\n",
      "    data_binary[np.logical_and(np.logical_not(data_binary==-1),np.isfinite(data_binary))]=  0\n",
      "    data_binary[data_binary==-1]=  1\n",
      "    \n",
      "    #correct for bias?\n",
      "    data_binary_corrected= np.copy(data_binary)\n",
      "    #no need for correction anymore? TODO\n",
      "    #for i in range(0,data.shape[0]):\n",
      "    #np.random.shuffle(data_binary_corrected[i,0:4])\n",
      "    \n",
      "    #--important summaries\n",
      "    #raw mean - exclude nans in first go, but may have some cols (esp. ends)... \n",
      "        #...with NO finte - need to exclude again\n",
      "    label_mean_profile= stats.nanmean(data_binary_corrected) #data\n",
      "    label_mean_profile= label_mean_profile[np.isfinite(label_mean_profile)]\n",
      "    \n",
      "    #errors for raw mean\n",
      "    #TODO - is this approach correct?? What about for small p, n?\n",
      "    from statsmodels.stats import proportion as prop\n",
      "    label_l_err= np.zeros(label_mean_profile.size)\n",
      "    label_r_err= np.zeros(label_mean_profile.size)\n",
      "    num_finite_rows= np.sum(np.isfinite(data),axis=0)\n",
      "    for i in range(0,label_mean_profile.size):\n",
      "        p_interval= prop.proportion_confint(label_mean_profile[i]*num_finite_rows[i],num_finite_rows[i],0.05)\n",
      "        label_l_err[i]= label_mean_profile[i]-p_interval[0]\n",
      "        label_r_err[i]= p_interval[1]-label_mean_profile[i]\n",
      "    label_l_err[label_l_err<0] = 0 #stop error bars going below zero\n",
      "    label_r_err[label_r_err>1] = 1 #stop error bars going above one. Not use of namean above means 1 unlabelled will have \n",
      "    \n",
      "    #--fitting\n",
      "    #fit smoothed function\n",
      "    label_mean_profile_to_fit= np.copy(label_mean_profile)\n",
      "    epsl= 0.00001\n",
      "    #avoid exactly zero and exactly one values in logit. TODO: bad?\n",
      "    label_mean_profile_to_fit[label_mean_profile_to_fit==0] = epsl \n",
      "    label_mean_profile_to_fit[label_mean_profile_to_fit==1] = 1-epsl \n",
      "    x_fit= np.arange(0,label_mean_profile_to_fit.size) #Will be full size since *at least one* non-nan in each set of samples\n",
      "    \n",
      "    #from statsmodels import api as sm\n",
      "    #lowess = sm.nonparametric.lowess\n",
      "    #label_smoothed_f_lgt= lowess(label_mean_profile_to_fit,x_fit,is_sorted=True)\n",
      "    #label_smoothed_f = lambda x: label_smoothed_f_lgt(x)#special.expit(\n",
      "    #from import statsmodels.api as sm\n",
      "    #lowess = sm.nonparametric.lowess\n",
      "    \n",
      "    #TODO - go back over spline options again\n",
      "    #m= 15\n",
      "    #s= m-np.sqrt(2*m)\n",
      "    \n",
      "    #-Spline with smoothing parameter style\n",
      "    label_smoothed_f_lgt= interpolate.UnivariateSpline(x_fit,special.logit(label_mean_profile_to_fit),k=k, s=s)\n",
      "    label_smoothed_f = lambda x: special.expit(label_smoothed_f_lgt(x))\n",
      "    #label_smoothed_f_lgt= interpolate.UnivariateSpline(x_fit,label_mean_profile_to_fit,k=3,s=0.003)\n",
      "    #label_smoothed_f = lambda x: label_smoothed_f_lgt(x)\n",
      "    \n",
      "    #-Lowess based\n",
      "    #from statsmodels import api as sm\n",
      "    #lowess = sm.nonparametric.lowess\n",
      "    #print x_fit\n",
      "    #print label_mean_profile_to_fit\n",
      "    #label_smoothed_lgt= lowess(special.logit(label_mean_profile_to_fit),x_fit,return_sorted=False,frac=1)\n",
      "    #print label_smoothed_lgt\n",
      "    #label_smoothed_f_lgt= interpolate.UnivariateSpline(x_fit,label_smoothed_lgt,k=3)\n",
      "    #label_smoothed_f = lambda x: special.expit(label_smoothed_f_lgt(x))\n",
      "    \n",
      "    #-Knot based\n",
      "    #label_mean_profile_to_fit\n",
      "    #t = np.floor(np.linspace(x_fit[0]+(x_fit[-1]-x_fit[0])*0.05,(x_fit[-1]-x_fit[0])*0.95+x_fit[0],10))# [5,10,15,20,25,30,50]\n",
      "    #print t\n",
      "    #if (do_log == True):\n",
      "    #    label_smoothed_f_lgt= interpolate.LSQUnivariateSpline(x_fit,special.logit(label_mean_profile_to_fit),t)#, s=s)\n",
      "    #    label_smoothed_f = lambda x: special.expit(label_smoothed_f_lgt(x))\n",
      "    #else:\n",
      "    #    label_smoothed_f_lgt= interpolate.LSQUnivariateSpline(x_fit,label_mean_profile_to_fit,t)#, s=s)\n",
      "    #    label_smoothed_f = lambda x: label_smoothed_f_lgt(x)\n",
      "\n",
      "    #--plots TODO\n",
      "    if do_plot:\n",
      "        \n",
      "        x= np.arange(0,label_mean_profile.size)\n",
      "        num_rows= data_binary.shape[0]\n",
      "        x_matrix_plotting= np.tile(x,[num_rows,1])\n",
      "        \n",
      "        #raw data\n",
      "        plt.figure()\n",
      "        plt.plot(x,label_mean_profile,'-',linewidth=2)\n",
      "        plt.plot(x_matrix_plotting,data_binary,'b.')\n",
      "\n",
      "        plt.xlabel('crypt-villus axis (cell number)')\n",
      "        plt.ylabel('labelled fraction')\n",
      "        plt.title('Labelled cell counts and labelled cell fractions along crypt-villus axis')\n",
      "        plt.xlim(x_min,x_max)\n",
      "        plt.ylim(y_min-0.01,y_max+0.01)\n",
      "        \n",
      "        save_path= output_path+sample_type+'/'\n",
      "        try:\n",
      "            os.makedirs(save_path)\n",
      "        except OSError as exc: # Python >2.5\n",
      "            if exc.errno == errno.EEXIST and os.path.isdir(save_path):\n",
      "                pass\n",
      "            else: raise\n",
      "        plt.savefig(save_path+'binary-labelled-fraction-profile-'+file_to_fit[:-4]+'.pdf')\n",
      "        plt.close()\n",
      "        \n",
      "        #smoothed with raw error bars\n",
      "        plt.figure()\n",
      "        plt.plot(x,label_smoothed_f(x),'r',label='smoothed')\n",
      "        plt.fill_between(x,label_mean_profile-label_l_err, label_mean_profile+label_r_err,edgecolor='#1B2ACC', facecolor='#089FFF')\n",
      "        plt.plot([],[],color='#1B2ACC',label='raw interval')\n",
      "        #raw markers\n",
      "        plt.plot(x,label_mean_profile,'bx',label='raw mean',markersize=3)\n",
      "        \n",
      "        plt.xlim(x_min,x_max)\n",
      "        plt.ylim(y_min,y_max)\n",
      "\n",
      "        plt.legend()#(['smoothed','raw'])\n",
      "        plt.xlabel('crypt-villus axis (cell number)')\n",
      "        plt.ylabel('labelled fraction')\n",
      "        plt.title('Profile of labelled fraction of cells along crypt-villus axis')\n",
      "\n",
      "        try:\n",
      "            os.makedirs(save_path)\n",
      "        except OSError as exc: # Python >2.5\n",
      "            if exc.errno == errno.EEXIST and os.path.isdir(save_path):\n",
      "                pass\n",
      "            else: raise\n",
      "        plt.savefig(save_path+'labelled-fraction-profile-'+file_to_fit[:-4]+'.pdf')\n",
      "        plt.close()\n",
      "    return label_mean_profile, label_l_err, label_r_err, label_smoothed_f\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_sample_sizes_for_data_file(data_dir='../data-working/TXT_BrdU/',file_to_fit='BrdU_01_0060min.txt',sample_type='BrdU',output_path='../figures/sample_size_profiles/',k=3,s=15,x_min=0.0,x_max=90.0,y_min=0.0,y_max=1.0,do_plot=False):\n",
      "    '''\n",
      "    Return sample sizes at each point at each time.\n",
      "    Calculate in column matrix format, then flatten? \n",
      "    Each column is the space grid of sample sizes at a fixed time (column index).\n",
      "    Same (or should be) as for residuals.\n",
      "\n",
      "    Inputs:\n",
      "    Read data from one file (time point)\n",
      "    Note - \n",
      "    rows: strips\n",
      "    cols: x locations\n",
      "    \n",
      "    '''\n",
      "    #--basic processing\n",
      "    #read in\n",
      "    data_panda= pd.read_csv(data_dir+file_to_fit,header=None,names=range(int(x_max)),dtype='float')\n",
      "    data= data_panda.values\n",
      "    \n",
      "    #sum over rows -> return vector\n",
      "    return np.sum(np.isfinite(data),axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#get_sample_sizes_for_data_file()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "    from scipy import stats\n",
      "    import os, errno #for file I/O and error handling - see: http://stackoverflow.com/questions/600268/mkdir-p-functionality-in-python\n",
      "    import scipy.interpolate as interpolate\n",
      "    import scipy.special as special\n",
      "    \n",
      "    #--basic processing\n",
      "    #read in\n",
      "    #data= np.genfromtxt(data_dir+file_to_fit,delimiter=\",\") #Load data from a text file, with missing values handled as specified\n",
      "    print 'here'\n",
      "    print data_dir+file_to_fit\n",
      "    data_panda= pd.read_csv(data_dir+file_to_fit,header=None,names=range(int(x_max)),dtype='float')\n",
      "    #data_panda.convert_objects(convert_numeric=True)\n",
      "    data= data_panda.values\n",
      "    \n",
      "    #print data\n",
      "    #print data[0,:]\n",
      "    \n",
      "    #convert to binary labelled/unlabelled (careful of NAs! - E.g. for lengths doesn't work.)\n",
      "    data_binary= np.copy(data[:,:]) #separate copies! Re tags vs. variables.\n",
      "    #data_binary[np.logical_or(data_binary==8,data_binary==2)] = -1\n",
      "    data_binary[(data_binary==2)|(data_binary==3)|(data_binary==8)|(data_binary==9)]=-1\n",
      "    data_binary[np.logical_and(np.logical_not(data_binary==-1),np.isfinite(data_binary))]=  0\n",
      "    data_binary[data_binary==-1]=  1\n",
      "    \n",
      "    #correct for bias?\n",
      "    data_binary_corrected= np.copy(data_binary)\n",
      "    #no need for correction anymore? TODO\n",
      "    #for i in range(0,data.shape[0]):\n",
      "    #np.random.shuffle(data_binary_corrected[i,0:4])\n",
      "    \n",
      "    #--important summaries\n",
      "    #raw mean - exclude nans in first go, but may have some cols (esp. ends)... \n",
      "        #...with NO finte - need to exclude again\n",
      "    label_mean_profile= stats.nanmean(data_binary_corrected) #data\n",
      "    label_mean_profile= label_mean_profile[np.isfinite(label_mean_profile)]\n",
      "    \n",
      "    #errors for raw mean\n",
      "    #TODO - is this approach correct?? What about for small p, n?\n",
      "    from statsmodels.stats import proportion as prop\n",
      "    label_l_err= np.zeros(label_mean_profile.size)\n",
      "    label_r_err= np.zeros(label_mean_profile.size)\n",
      "    num_finite_rows= np.sum(np.isfinite(data),axis=0)\n",
      "    for i in range(0,label_mean_profile.size):\n",
      "        p_interval= prop.proportion_confint(label_mean_profile[i]*num_finite_rows[i],num_finite_rows[i],0.05)\n",
      "        label_l_err[i]= label_mean_profile[i]-p_interval[0]\n",
      "        label_r_err[i]= p_interval[1]-label_mean_profile[i]\n",
      "    label_l_err[label_l_err<0] = 0 #stop error bars going below zero\n",
      "    label_r_err[label_r_err>1] = 1 #stop error bars going above one. Not use of namean above means 1 unlabelled will have \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}